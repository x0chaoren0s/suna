# 跨终端记忆通信协议 (Cross-Terminal Memory Protocol)

**版本**: 1.0.0  
**最后更新**: 2025-11-16  
**适用对象**: AI助手（Claude/Cursor）

---

## 1. 协议概述

### 1.1 系统目的

本协议旨在实现多个工作终端间的开发经验和知识共享，使开发者在不同终端（本地电脑、远程服务器等）之间切换时，能够无缝继承之前的工作上下文和积累的知识。

### 1.2 核心理念

**目标体验**: 在不同终端工作应如同在单一终端工作，完全无感知终端的切换。

**设计原则**:
- **简洁性**: 命令和输出保持精炼，但包含实质内容
- **自动化**: 尽可能自动化，减少手动干预
- **智能性**: AI理解上下文，做出合理判断
- **可控性**: 关键决策保留人工确认

### 1.3 系统架构

```
用户在终端A工作 → HARVEST命令 → 记忆写入文件 → Git推送
                                                    ↓
用户切换到终端B → SYNC命令 → Git拉取 → 学习记忆 → 开始工作
```

---

## 2. 核心概念

### 2.1 记忆分层体系

记忆系统采用三层架构，每层有不同的生命周期和用途：

#### 短期记忆（生命周期：7天）

**定义**: 临时的、进行中的工作上下文

**包含内容**:
- 正在进行但未完成的任务
- 待验证的假设和方案
- 临时的调试发现
- 需要跨会话追踪的问题

**示例**:
- "数据库查询优化进行中：开发环境有效，待生产验证"
- "WebSocket连接池调试：发现内存泄漏，正在追踪"
- "API限流方案评估：考虑Redis vs 内存实现"

**生命周期管理**:
- 7天后如果相关工作已完成 → 提升为中期记忆
- 7天后如果已过时/不再相关 → 自动遗忘
- 可以手动标记为重要，延长生命周期

#### 中期记忆（生命周期：项目周期内）

**定义**: 项目级别的知识和经验

**包含内容**:
- 架构决策及其原因
- 环境配置差异（本地vs服务器）
- 已解决的问题和方案
- 依赖关系和版本约束
- 部署流程和注意事项
- 性能优化经验
- 已知问题和限制

**示例**:
- "Redis集成完成：Sentinel模式，3节点配置，用于会话和API缓存"
- "服务器Python环境为3.10，本地为3.12，注意asyncio兼容性"
- "登录bug修复：Token过期判断需使用UTC时间"
- "大数据集分页：使用游标而非offset，性能提升10倍"

**融合机制**:
- 所有终端都学习过的中期记忆 → 融入综合记忆
- 融入时进行提炼和压缩，保持精简

#### 长期记忆（综合记忆）

**定义**: 高度提炼的、跨项目适用的通用知识

**包含内容**:
- 通用的最佳实践
- 工具使用技巧
- 常见问题的解决模式
- 技术选型经验

**示例**:
- "缓存策略：会话用Redis，静态资源用CDN，数据库查询用应用层缓存"
- "异步任务：Celery适合复杂工作流，简单任务用asyncio"
- "部署流程：健康检查 → 灰度发布 → 全量部署 → 回滚准备"

**特点**:
- 高度精简，避免冗余
- 每次融入新记忆时重新提炼
- 对抗信息熵增

### 2.2 终端标识

**格式**: 【计算机名：环境名】

**示例**:
- 【小黑：本地】- 小黑电脑的本地开发环境
- 【小黑：ubuntu】- 小黑电脑连接的Ubuntu服务器
- 【大黑：本地】- 大黑电脑的本地开发环境
- 【大黑-毕业：ubuntu】- 大黑毕业项目的服务器环境

**生成规则**:
1. 自动检测主机名（hostname）
2. 首次使用时询问用户环境名称
3. 生成唯一的terminal_id（如：xiaohei_ubuntu）
4. 配置到 system.json（终端本地配置）

### 2.3 记忆生命周期

```
工作产生变更
    ↓
HARVEST → 生成记忆 → 分类（短期/中期/长期）
    ↓
写入归档文件（按终端）
    ↓
更新活跃记忆文件（按层级）
    ↓
Git推送到memory分支
    ↓
其他终端SYNC → 学习记忆
    ↓
所有终端都学习后
    ↓
中期记忆 → 融入综合记忆（提炼压缩）
    ↓
短期记忆超过7天 → 提升或遗忘
```

---

## 3. AI助手行为规范

### 3.1 命令识别

当用户发送以下任一表述时，识别为记忆系统命令：

**SYNC命令**:
- "SYNC"
- "同步记忆"
- "学习新知识"
- "更新记忆"

**HARVEST命令**:
- "HARVEST"
- "收获记忆"
- "总结记忆"
- "保存经验"

**CONSOLIDATE命令**:
- "CONSOLIDATE"
- "整理记忆"
- "清理记忆"

**STATUS命令**:
- "MEMORY STATUS"
- "记忆状态"
- "查看记忆"

### 3.2 核心执行原则

#### 原则1：基于实际而非对话

**关键要求**: 执行HARVEST时，不应依赖当前session的对话历史，而应基于项目的实际变化。

**为什么**: 用户可能在多个chat session中工作，依赖单一session的对话历史会导致信息不完整或不准确。

**正确做法**:
1. 调用脚本分析Git提交历史
2. 检查任务文件（.tasks/）的变更
3. 扫描工作目录的实际变化
4. 基于这些客观数据生成记忆

**示例对比**:

❌ **错误方式**（依赖对话历史）:
```
"根据我们刚才的对话，你完成了Redis集成和登录bug修复..."
```
问题：如果用户用了多个session，这个判断就不准确。

✅ **正确方式**（基于实际变化）:
```
"根据Git提交记录分析：
- 3个提交涉及Redis配置文件（config/redis.py, utils/cache.py）
- 任务文件显示Redis集成任务状态为completed
- 1个提交修改了auth/token_validator.py
推断：你完成了Redis集成和登录相关修复

是否还有其他重要的经验或决策需要记录？"
```

#### 原则2：简洁但有实质

**关键要求**: 输出应简洁，但必须包含实质内容，不能只是数字统计。

**示例对比**:

❌ **错误方式**（太简洁，无实质）:
```
✓ 同步完成，学习了5条新记忆
```

✅ **正确方式**（简洁且有实质）:
```
✓ 同步完成 | 终端：【小黑：ubuntu】| 学习了 5 条新记忆

来自【大黑：本地】(2025-11-15):
  • Redis集成完成：Sentinel模式
  • 登录bug修复：Token时区问题
  • 部署脚本优化：增加健康检查

来自【小黑：本地】(2025-11-14):
  • 依赖冲突解决：NumPy锁定1.24.3
  • API限流策略：Redis令牌桶算法
```

**格式要求**:
- 每条记忆用5-10个字的主题 + 可选的10-20字关键细节
- 不超过30字/条
- 突出关键词

#### 原则3：智能判断重要性

**关键要求**: 不是所有变更都需要记录，需要智能过滤琐碎的修改。

**应该记录的变更**:
- ✅ 新功能实现
- ✅ 非显而易见的Bug修复
- ✅ 架构调整或重构
- ✅ 影响部署的配置变更
- ✅ 性能优化（有明显效果的）
- ✅ 重要的技术决策及原因
- ✅ 已知问题和限制
- ✅ 环境差异导致的特殊处理

**不应该记录的变更**:
- ❌ 纯格式调整（缩进、空行、代码风格）
- ❌ 简单的注释添加或修改
- ❌ 显而易见的typo修复（变量名拼写错误等）
- ❌ 临时调试代码的添加和删除（console.log, print等）
- ❌ 非关键的变量或函数重命名
- ❌ 依赖包的例行更新（无breaking change）

**判断示例**:

场景1：提交信息"fix typo in variable name"
- 分析：显而易见的拼写修复
- 判断：不记录 ❌

场景2：提交信息"fix login bug"，修改了token验证逻辑
- 分析：涉及业务逻辑的bug修复
- 判断：应记录，需了解根因 ✅

场景3：提交信息"refactor cache module"，重构了缓存层
- 分析：架构级别的调整
- 判断：应记录，需了解重构原因和新架构 ✅

场景4：多个提交都是"wip"或"temp"
- 分析：临时性的工作进展
- 判断：如果最终完成了有意义的功能，记录最终结果而非过程 ✅

#### 原则4：保持终端一致性

**关键要求**: 所有终端的AI应输出一致的格式和风格。

**统一要求**:
- 终端标识：【计算机名：环境名】
- 时间格式：YYYY-MM-DD HH:MM（东八区UTC+8显示）
- 成功标记：✓
- 警告标记：⚠️

**时间处理规则**:
- **存储格式**：UTC时间（ISO 8601标准，如 `2025-11-17T05:13:33Z`）
- **显示格式**：东八区时间（UTC+8，如 `2025-11-17 13:13`）
- **转换方法**：显示时自动加8小时
- **原因**：保持国际标准，便于跨时区协作

**时间获取标准方法**：
- **严禁手动编造时间**：必须使用系统命令获取实际当前时间
- **示例输出**：`2025-11-17T07:57:39Z`
- **显示转换**：将UTC时间加8小时后以 `YYYY-MM-DD HH:MM` 格式显示

**跨平台时间获取命令**：

**推荐方案**（已测试通过，全平台兼容）：

```bash
# 通用Python方案 - Ubuntu/PowerShell/CMD 均可用
python -c "import datetime; print(datetime.datetime.now(datetime.UTC).strftime('%Y-%m-%dT%H:%M:%SZ'))"
```

**备选方案**（按平台）：

1. **Linux/macOS/Git Bash**：
   ```bash
   date -u +"%Y-%m-%dT%H:%M:%SZ"
   ```

2. **Windows PowerShell**（旧版本兼容）：
   ```powershell
   (Get-Date).ToUniversalTime().ToString('yyyy-MM-ddTHH:mm:ssZ')
   ```

3. **Windows PowerShell**（新版本，PowerShell 7+）：
   ```powershell
   Get-Date -Format 'yyyy-MM-ddTHH:mm:ssZ' -AsUTC
   ```

**AI执行建议**：
- **优先使用Python通用方案**（已验证跨平台兼容）
- 如果Python不可用，根据操作系统选择备选方案
- Linux/macOS 优先 `date -u` 命令
- Windows 优先 PowerShell 兼容命令
- 确保获取的是UTC时间（带 `Z` 后缀）
- 列表标记：•（bullet point）
- 记忆描述风格：简短、准确、关键词突出

#### 原则5：主动提示但不强制

**关键要求**: 在适当时机提示用户使用记忆系统，但不打断工作流程。

**应该提示的情况**:
- 检测到大量Git提交但长时间（超过4小时）未HARVEST
- 新的一天开始工作但尚未SYNC（超过12小时）
- 发现记忆冲突需要用户确认

**提示方式**:
- 温和的建议，不使用命令语气
- 可以忽略，不强制执行
- 放在响应的末尾，不干扰主要内容

**示例**:
```
（主要响应内容）
...

💡 提示：检测到自上次HARVEST以来已有8个新提交，建议在工作结束时执行HARVEST保存经验。
```

### 3.3 输出格式规范

#### 通用格式要求

1. **符号使用**:
   - ✓ 表示成功操作
   - ⚠️ 表示需要注意的事项
   - 【】标记终端名称
   - • (bullet point) 列举记忆条目
   - | 分隔元数据字段

2. **布局要求**:
   - 保持对齐和缩进一致
   - 使用空行分隔不同部分
   - 来源终端分组显示

3. **时间格式**:
   - 完整时间：YYYY-MM-DD HH:MM（东八区UTC+8）
   - 仅日期：YYYY-MM-DD
   - 注意：存储为UTC，显示时转换

#### 记忆描述格式

**标准格式**:
```
主题（5-10字）：关键细节（可选，10-20字）
```

**示例**:
- "Redis集成完成：Sentinel模式，3节点"
- "登录bug修复：Token时区问题"
- "查询优化进行中：待生产验证"
- "部署流程更新：增加健康检查"
- "依赖冲突解决：NumPy锁定1.24.3"

#### 禁止的输出方式

❌ 不要使用表情符号（除了✓和⚠️）  
❌ 不要使用模糊描述（如"一些优化"、"若干修改"、"相关工作"）  
❌ 不要输出过长的文本（单条记忆描述不超过30字）  
❌ 不要输出代码片段（除非用户明确要求）  
❌ 不要在记忆命令的输出中添加其他无关信息  
❌ 不要使用主观评价（如"很好的优化"、"完美的解决方案"）

---

## 4. 核心命令执行指南

### 4.1 SYNC（同步记忆）

#### 触发条件

用户发送"SYNC"、"同步记忆"或相关表述。

#### 适用场景

- 在新终端开始工作前
- 长时间（超过12小时）未同步时
- 怀疑其他终端有新知识需要学习时

#### 执行步骤

**步骤1：前置检查**

检查记忆系统是否已初始化：
```python
if not os.path.exists('.memory/'):
    # 系统未初始化
    提示用户初始化
    return
```

输出示例：
```
⚠️ 记忆系统尚未初始化

检测到这是首次使用跨终端记忆系统。
是否现在初始化？（将创建.memory/目录和相关配置）

回复"是"或"初始化"以开始。
```

**步骤2：检测当前终端**

```python
terminal_info = detect_current_terminal()
# 返回：{"hostname": "xiaohei", "environment": "ubuntu", "terminal_id": "xiaohei_ubuntu"}
```

如果是新终端（首次使用）：
```
检测到新终端：xiaohei

请输入环境名称（如：本地、ubuntu、生产等）：
```

**步骤3：Git拉取最新记忆**

```bash
git fetch origin memory
git checkout memory
git pull origin memory
```

如果有冲突，自动合并或提示用户。

**步骤4：识别未学习的记忆**

读取`index/learning_status.json`，找出：
- `learned_by`列表中不包含当前终端ID的记忆
- 且状态为`active`的记忆

**步骤5：判断是否为新终端首次同步**

```python
if terminal_id not in learning_status["terminals"]:
    # 新终端首次同步
    is_first_sync = True
else:
    is_first_sync = False
```

**步骤6：学习记忆**

**情况A：新终端首次同步**

学习范围：
- 综合记忆（全量）
- 近7天的短期记忆

输出格式：
```
✓ 新终端初始化 | 终端：【小黑：ubuntu】

已学习综合记忆：
  架构：Django REST + Redis + PostgreSQL
  部署：Docker Compose + Nginx
  关键配置：环境变量见 .env.example
  已知问题：大数据集分页需特殊处理

近期工作 (最近7天):
  • Redis集成完成、登录修复、查询优化
  • Nginx配置更新、部署脚本优化
  • 依赖管理、API限流策略

准备就绪 ✓
```

**情况B：常规同步**

学习范围：
- 所有未学习的记忆（按时间顺序）

如果有新记忆，输出格式：
```
✓ 同步完成 | 终端：【小黑：ubuntu】| 学习了 4 条新记忆

来自【大黑：本地】(2025-11-15):
  • Nginx反向代理配置：HTTPS证书自动续期
  • 部署脚本优化：增加健康检查和回滚

来自【小黑：本地】(2025-11-14):
  • 依赖冲突解决：NumPy版本锁定1.24.3
  • API限流策略：Redis令牌桶算法

⚠️ 注意：服务器Python环境为3.10，本地为3.12，注意兼容性
```

如果没有新记忆，输出格式：
```
✓ 同步完成 | 终端：【小黑：ubuntu】

所有记忆已是最新，无需学习
最后更新：2025-11-16 by 【小黑：ubuntu】
```

**步骤7：更新学习状态**

将当前终端ID添加到已学习记忆的`learned_by`列表中。

**重要**：使用系统命令获取实际当前时间更新 last_sync（参考协议第296-327行的跨平台命令）：
```bash
# 推荐：通用Python方案（全平台测试通过）
python -c "import datetime; print(datetime.datetime.now(datetime.UTC).strftime('%Y-%m-%dT%H:%M:%SZ'))"

# 备选：Linux/macOS/Git Bash
date -u +"%Y-%m-%dT%H:%M:%SZ"

# 备选：Windows PowerShell（旧版本兼容）
(Get-Date).ToUniversalTime().ToString('yyyy-MM-ddTHH:mm:ssZ')
```

更新`learning_status.json`和`system.json`：
```json
{
  "terminals": {
    "xiaohei_ubuntu": {
      "last_sync": "2025-11-16T09:00:23Z",
      "learned_memory_ids": ["mem_20251116_001", "mem_20251116_002", ...],
      "pending_learn": []
    }
  }
}
```

#### 特殊情况处理

**情况1：网络问题无法拉取**
```
⚠️ 同步失败：无法连接到远程仓库

请检查网络连接或稍后重试。
本地记忆仍然可用。
```

**情况2：发现记忆冲突**

如果检测到不同终端对同一问题有不同的见解：
```
✓ 同步完成 | 终端：【小黑：ubuntu】| 学习了 3 条新记忆

来自【大黑：本地】(2025-11-15):
  • Redis配置优化：调整连接池大小为200
  • ...

⚠️ 注意：检测到可能的配置冲突
  - 【大黑：本地】设置Redis连接池为200
  - 【小黑：本地】之前设置为100
  请确认哪个配置更合适，或根据环境区分。
```

### 4.2 HARVEST（收获记忆）

#### 触发条件

用户发送"HARVEST"、"收获记忆"或相关表述。

#### 适用场景

- 完成一段时间的工作，准备离开终端
- 完成了重要的任务或解决了问题
- 一天工作结束时

#### 前置检查

1. 检查记忆系统是否已初始化
2. 检查当前终端是否已注册
3. 检查能否切换到memory分支

#### 执行步骤

**步骤1：读取上次HARVEST时间**

从`config/system.json`或`logs/harvest_log.json`读取本终端的上次HARVEST时间。

**步骤2：分析自上次以来的变更**

调用脚本进行分析：
```bash
python .memory_scripts/memory_manager.py analyze-changes \
  --since "2025-11-15 18:30:00" \
  --terminal "xiaohei_ubuntu"
```

脚本会分析：
- Git提交历史（提交信息、修改文件、时间戳）
- 任务文件变更（.tasks/目录）
- 未提交的变更（git diff）
- 可能的配置文件变更

返回JSON格式的分析结果。

**步骤3：智能分析和分类**

AI基于分析结果进行推断：

1. **识别完成的工作**：
   - 从提交信息中提取关键词
   - 关联任务文件的完成状态
   - 推断完成了哪些具体工作

2. **识别进行中的工作**：
   - 从未提交的变更推断
   - 从新建但未完成的任务文件识别

3. **评估重要性**：
   - 应用"原则3"的判断标准
   - 过滤琐碎的修改

4. **分类记忆层级**：
   - 完成的重要工作 → 中期记忆
   - 进行中的工作 → 短期记忆
   - 通用经验（较少） → 长期记忆

**步骤4：与用户确认（交互式）**

生成初步的记忆摘要，向用户展示并确认：

```
观察到你在这个终端上进行了以下工作：

已完成（拟记录为中期记忆）：
1. Redis集成：检测到3个提交修改config/redis.py、utils/cache.py
   推断：实现了Redis缓存层，可能使用Sentinel模式
   
2. 登录bug修复：检测到1个提交修改auth/token_validator.py
   推断：修复了Token验证相关问题

进行中（拟记录为短期记忆）：
3. 数据库查询优化：检测到config/database.py有未提交修改
   推断：正在进行查询优化配置

是否还有其他重要的经验、决策或需要记录的信息？
如果以上推断有误，请指出修正。
```

用户可能的回应：
- 补充细节："是的，第3点我担心生产环境可能有问题"
- 修正分类："第2点不是bug修复，是功能优化"
- 确认："没有了，就这些"
- 补充新的："还有一个XXX"

**步骤5：生成结构化记忆数据**

基于确认后的信息，生成结构化的记忆。

**重要**：使用系统命令获取实际当前时间，禁止手动编造。

**跨平台命令**（参考协议第296-327行）：
```bash
# 推荐：通用Python方案（全平台测试通过）
python -c "import datetime; print(datetime.datetime.now(datetime.UTC).strftime('%Y-%m-%dT%H:%M:%SZ'))"

# 备选：Linux/macOS/Git Bash
date -u +"%Y-%m-%dT%H:%M:%SZ"

# 备选：Windows PowerShell（旧版本兼容）
(Get-Date).ToUniversalTime().ToString('yyyy-MM-ddTHH:mm:ssZ')

# 输出示例：2025-11-16T18:45:23Z
```

生成的记忆数据结构：

```json
{
  "harvest_time": "2025-11-16T18:45:23Z",
  "terminal": "xiaohei_ubuntu",
  "memories": [
    {
      "type": "medium_term",
      "category": "architecture",
      "title": "Redis集成完成",
      "summary": "Redis集成完成：Sentinel模式，3节点配置",
      "details": "完成Redis缓存层集成，采用Sentinel模式实现高可用...",
      "tags": ["redis", "cache", "deployment"],
      "related_commits": ["abc123", "def456"],
      "related_files": ["config/redis.py", "utils/cache.py"]
    },
    {
      "type": "short_term",
      "category": "work_in_progress",
      "title": "数据库查询优化进行中",
      "summary": "查询优化进行中：待生产验证",
      "details": "优化用户列表查询，开发环境有效（200ms→50ms），担心生产环境数据量更大...",
      "tags": ["database", "optimization"],
      "status": "in_progress"
    }
  ]
}
```

**步骤6：保存记忆**

调用脚本保存：
```bash
python .memory_scripts/memory_manager.py harvest --data '<JSON数据>'
```

脚本执行：
1. 生成唯一记忆ID
2. 写入归档文件：`archives/xiaohei_ubuntu/2025-11-16_001.md`
3. 更新记忆索引：`index/memory_index.json`
4. 更新活跃记忆：`active/short_term.md`、`active/medium_term.md`
5. 更新学习状态：标记本终端已学习这些记忆
6. Git提交：`git commit -m "HARVEST: 【小黑：ubuntu】@ 2025-11-16 18:45 - Redis集成、登录修复等"`
7. Git推送：`git push origin memory`

**步骤7：向用户报告**

使用标准输出格式：

```
✓ 已收获记忆 | 终端：【小黑：ubuntu】| 2025-11-16 18:45

中期记忆 (2条):
  • Redis集成完成：Sentinel模式，3节点配置
  • 登录bug修复：Token过期判断逻辑

短期记忆 (1条):
  • 查询优化进行中：待生产验证

已推送到 origin/memory
```

#### 特殊情况处理

**情况1：无重要变更**

```
✓ 已扫描工作记录 | 终端：【小黑：ubuntu】| 2025-11-16 12:30

本次无重要记忆需要记录（仅有代码格式调整等琐碎变更）
```

**情况2：Git推送失败**

```
✓ 已收获记忆 | 终端：【小黑：ubuntu】| 2025-11-16 18:45

中期记忆 (2条):
  • Redis集成完成：Sentinel模式，3节点配置
  • 登录bug修复：Token过期判断逻辑

⚠️ 注意：记忆已保存到本地，但推送到远程失败（网络问题）
下次SYNC或HARVEST时会自动重试推送
```

**情况3：多session工作**

用户可能在多个chat session中工作，AI无法依赖对话历史：

```
观察到你在这个终端上有多个Git提交：

已完成（基于代码变更推断）：
1. Redis相关：3个提交，涉及config/redis.py等文件
2. 认证相关：1个提交，修改auth/token_validator.py

由于无法获取完整上下文，请补充以下信息：
- 这些工作的具体目的和成果？
- 是否遇到了需要记录的问题或决策？
- 是否有特殊的注意事项？
```

### 4.3 CONSOLIDATE（整理记忆）

#### 触发条件

- 用户发送"CONSOLIDATE"、"整理记忆"
- 系统自动触发（每7天）

#### 目的

1. 处理过期的短期记忆
2. 将成熟的中期记忆融入综合记忆
3. 提炼和压缩，对抗信息熵增

#### 执行步骤

**步骤1：扫描短期记忆**

检查所有短期记忆的创建时间，找出超过7天的记忆。

**步骤2：评估短期记忆的处理方式**

对每条过期的短期记忆：

1. **检查相关工作是否完成**：
   - 搜索Git历史，看是否有相关的后续提交
   - 检查任务文件，看相关任务是否完成

2. **决策**：
   - 如果工作已完成 → 提升为中期记忆
   - 如果已不再相关 → 遗忘（删除）
   - 如果仍在进行但需要更长时间 → 标记为重要，延长生命周期

**步骤3：扫描中期记忆**

检查哪些中期记忆已被所有终端学习过。

**步骤4：融入综合记忆**

对于所有终端都学过的中期记忆：

1. **提取核心知识**：去除冗余细节，保留关键信息
2. **与现有综合记忆合并**：
   - 如果是新知识 → 添加
   - 如果是现有知识的更新 → 替换并重新提炼
   - 如果是相关知识 → 合并并压缩
3. **更新综合记忆文件**：`active/consolidated.md`

**步骤5：清理和归档**

- 遗忘的记忆移至归档
- 融入综合的中期记忆标记为archived
- 更新索引文件

**步骤6：Git提交并推送**

```bash
git commit -m "CONSOLIDATE: 整理记忆 - 处理X条短期，融合Y条中期"
git push origin memory
```

**步骤7：向用户报告**

```
✓ 记忆整理完成 | 2025-11-16

短期 → 中期 (3条):
  • 数据库查询优化：已验证，融入架构文档
  • WebSocket连接池：内存泄漏已修复，稳定运行
  • 日志格式统一：已全项目应用

中期 → 综合 (2条):
  • 部署流程：融入通用部署知识
  • 测试策略：提炼为最佳实践

遗忘 (1条):
  • 临时调试配置：已过期且不再需要

综合记忆已更新提炼 ✓
```

### 4.4 MEMORY STATUS（记忆状态）

#### 触发条件

用户发送"MEMORY STATUS"、"记忆状态"或相关表述。

#### 输出内容

```
记忆系统状态 | 终端：【小黑：ubuntu】

最后SYNC：2025-11-16 09:00
最后HARVEST：2025-11-16 18:45
最后CONSOLIDATE：2025-11-10 20:00（自动）

当前记忆统计：
  短期记忆：3条（活跃）
  中期记忆：15条（本终端参与产生：5条）
  综合记忆：已融合8个主题

待推送：0条（所有记忆已同步）
待学习：2条新记忆来自【大黑：本地】

建议：有新记忆待学习，可执行SYNC
```

---

## 5. 记忆判断标准

### 5.1 什么应该记录

#### 类型1：架构和设计决策

**标准**：
- 影响系统结构的决策
- 技术选型及其原因
- 模块划分和接口设计

**示例**：
- ✅ "选择Redis Sentinel而非Cluster：当前数据量不需要分片"
- ✅ "API设计采用RESTful：考虑前端团队熟悉度"
- ✅ "数据库索引策略：复合索引 (user_id, created_at)"

#### 类型2：非显而易见的Bug修复

**标准**：
- 需要分析才能定位的问题
- 根本原因不明显的bug
- 可能在其他地方重现的问题

**示例**：
- ✅ "登录bug修复：Token过期判断需使用UTC时间，本地和服务器时区不同"
- ✅ "内存泄漏修复：WebSocket连接未正确关闭，需在cleanup中显式断开"
- ❌ "修复拼写错误：usre → user"（显而易见，不记录）

#### 类型3：环境配置差异

**标准**：
- 本地和服务器环境的不同
- 需要特殊处理的配置
- 影响部署的环境依赖

**示例**：
- ✅ "服务器Python 3.10，本地3.12，asyncio.timeout行为不同"
- ✅ "生产环境Redis使用密码认证，本地不需要"
- ✅ "Nginx配置：服务器需要HTTPS，本地HTTP即可"

#### 类型4：性能优化

**标准**：
- 有明显效果的优化（如性能提升>20%）
- 优化的思路和方法
- 可能的副作用或限制

**示例**：
- ✅ "查询优化：添加复合索引，从200ms降至50ms"
- ✅ "大数据集分页：改用游标而非offset，性能提升10倍"
- ❌ "调整代码格式：无实质性能影响"（不记录）

#### 类型5：已知问题和限制

**标准**：
- 暂时无法解决的问题
- 已知的系统限制
- 需要后续改进的点

**示例**：
- ✅ "已知限制：并发超过1000时Redis连接池可能耗尽"
- ✅ "待改进：当前搜索未使用全文索引，大数据集性能差"

#### 类型6：重要的依赖管理

**标准**：
- 版本冲突的解决
- 关键依赖的选择原因
- 版本锁定的原因

**示例**：
- ✅ "NumPy锁定1.24.3：1.25+与现有代码不兼容"
- ✅ "选择FastAPI而非Flask：需要异步支持和自动API文档"
- ❌ "更新requests到2.31.0"（例行更新，无特殊原因，不记录）

### 5.2 什么不应该记录

#### 类型1：格式和风格调整

- ❌ 缩进调整
- ❌ 空行添加/删除
- ❌ 代码风格统一（除非是项目级别的重大重构）
- ❌ 注释格式调整

#### 类型2：显而易见的修改

- ❌ 简单的拼写错误修复
- ❌ 明显的变量名优化（如 x → user_count）
- ❌ 简单的函数提取（无架构影响）

#### 类型3：临时性工作

- ❌ 添加console.log/print调试
- ❌ 临时注释代码
- ❌ 测试用的mock数据

#### 类型4：例行操作

- ❌ 依赖包的例行更新（无breaking change）
- ❌ 定期的数据清理
- ❌ 日志轮转配置

### 5.3 记忆层级判断流程

```
新的变更或工作
    ↓
是否重要？（应用5.1和5.2的标准）
    ↓ 是
是否已完成？
    ├─ 是 → 中期记忆
    └─ 否 → 短期记忆
    
是否是通用经验（跨项目适用）？
    ↓ 是
    长期记忆（罕见，大多数记忆不会直接进入这一层）
```

**详细判断**：

**短期记忆的特征**：
- 工作进行中，尚未完成
- 需要后续验证或测试
- 临时性的发现或假设
- 需要跨会话追踪的问题

**中期记忆的特征**：
- 工作已完成并验证
- 对项目有明确价值
- 其他团队成员需要了解
- 可能影响后续开发

**长期记忆的特征**：
- 高度抽象和通用
- 跨项目适用
- 最佳实践或方法论
- 工具使用技巧

**注意**：大多数记忆开始是短期或中期，只有经过多次提炼才可能进入长期记忆。

---

## 6. 输出格式模板

### 6.1 SYNC输出模板

#### 模板1：有新记忆（常规场景）

```
✓ 同步完成 | 终端：【当前终端名】| 学习了 N 条新记忆

来自【终端A】(YYYY-MM-DD):
  • 记忆1简述：关键细节
  • 记忆2简述：关键细节
  • 记忆3简述：关键细节

来自【终端B】(YYYY-MM-DD):
  • 记忆4简述：关键细节

[可选] ⚠️ 注意：特别需要注意的事项
```

**实际示例**：

```
✓ 同步完成 | 终端：【小黑：ubuntu】| 学习了 4 条新记忆

来自【大黑：本地】(2025-11-15):
  • Nginx反向代理配置：HTTPS证书自动续期方案
  • 部署脚本优化：增加健康检查和回滚机制

来自【小黑：本地】(2025-11-14):
  • 依赖冲突解决：NumPy版本锁定1.24.3
  • API限流策略：Redis令牌桶算法

⚠️ 注意：服务器Python环境为3.10，本地为3.12，注意兼容性
```

#### 模板2：无新记忆

```
✓ 同步完成 | 终端：【当前终端名】

所有记忆已是最新，无需学习
最后更新：YYYY-MM-DD by 【终端名】
```

**实际示例**：

```
✓ 同步完成 | 终端：【小黑：ubuntu】

所有记忆已是最新，无需学习
最后更新：2025-11-16 by 【小黑：ubuntu】
```

#### 模板3：新终端首次同步

```
✓ 新终端初始化 | 终端：【当前终端名】

已学习综合记忆：
  架构：[简要描述]
  部署：[简要描述]
  关键配置：[简要描述]
  已知问题：[简要描述]

近期工作 (最近7天):
  • 记忆1、记忆2、记忆3...

准备就绪 ✓
```

**实际示例**：

```
✓ 新终端初始化 | 终端：【大黑-毕业：ubuntu】

已学习综合记忆：
  架构：Django REST + Redis + PostgreSQL + Celery
  部署：Docker Compose + Nginx反向代理
  关键配置：环境变量见.env.example，Redis需密码认证
  已知问题：并发>1000时连接池可能耗尽，大数据集分页需用游标

近期工作 (最近7天):
  • Redis集成、登录修复、查询优化
  • Nginx HTTPS配置、部署脚本健康检查
  • NumPy依赖管理、API限流实现

准备就绪 ✓
```

### 6.2 HARVEST输出模板

#### 模板1：有重要记忆

```
✓ 已收获记忆 | 终端：【当前终端名】| YYYY-MM-DD HH:MM

中期记忆 (N条):
  • 记忆简述：关键细节
  • 记忆简述：关键细节

短期记忆 (N条):
  • 记忆简述：关键细节

[可选] 长期记忆 (N条):
  • 记忆简述：关键细节

已推送到 origin/memory
```

**实际示例**：

```
✓ 已收获记忆 | 终端：【小黑：ubuntu】| 2025-11-16 18:45

中期记忆 (2条):
  • Redis集成完成：Sentinel模式，3节点配置
  • 登录bug修复：Token过期判断需用UTC时间

短期记忆 (1条):
  • 数据库查询优化进行中：索引方案待生产验证

已推送到 origin/memory
```

#### 模板2：无重要记忆

```
✓ 已扫描工作记录 | 终端：【当前终端名】| YYYY-MM-DD HH:MM

本次无重要记忆需要记录（仅有[简要说明琐碎变更类型]）
```

**实际示例**：

```
✓ 已扫描工作记录 | 终端：【小黑：ubuntu】| 2025-11-16 12:30

本次无重要记忆需要记录（仅有代码格式调整、注释补充等琐碎变更）
```

#### 模板3：推送失败

```
✓ 已收获记忆 | 终端：【当前终端名】| YYYY-MM-DD HH:MM

中期记忆 (N条):
  • 记忆简述：关键细节
  ...

⚠️ 注意：记忆已保存到本地，但推送到远程失败（原因）
下次SYNC或HARVEST时会自动重试推送
```

### 6.3 CONSOLIDATE输出模板

```
✓ 记忆整理完成 | YYYY-MM-DD

短期 → 中期 (N条):
  • 记忆简述：处理方式

中期 → 综合 (N条):
  • 记忆简述：融入结果

遗忘 (N条):
  • 记忆简述：遗忘原因

综合记忆已更新提炼 ✓
```

**实际示例**：

```
✓ 记忆整理完成 | 2025-11-16

短期 → 中期 (3条):
  • 数据库查询优化：已在生产验证通过，融入架构文档
  • WebSocket连接池：内存泄漏已修复，稳定运行7天
  • 日志格式统一：已全项目应用，提升可读性

中期 → 综合 (2条):
  • 部署流程文档化：融入通用部署知识
  • 测试覆盖率提升：提炼为测试最佳实践

遗忘 (1条):
  • 临时调试Redis配置：已过期14天且不再需要

综合记忆已更新提炼 ✓
```

### 6.4 STATUS输出模板

```
记忆系统状态 | 终端：【当前终端名】

最后SYNC：YYYY-MM-DD HH:MM
最后HARVEST：YYYY-MM-DD HH:MM
最后CONSOLIDATE：YYYY-MM-DD HH:MM（自动/手动）

当前记忆统计：
  短期记忆：N条（活跃）
  中期记忆：N条（本终端参与产生：N条）
  综合记忆：已融合N个主题

待推送：N条（描述）
待学习：N条新记忆来自【终端名】

[可选] 建议：具体建议
```

---

## 7. 特殊情况处理指南

### 7.1 系统未初始化

**检测**：`.memory/`目录不存在

**AI响应**：

```
⚠️ 记忆系统尚未初始化

检测到这是首次使用跨终端记忆系统。
是否现在初始化？（将创建.memory/目录和相关配置）

回复"是"或"初始化"以开始。
```

**初始化流程**：

1. 创建目录结构
2. 检测终端信息，询问环境名称
3. 生成配置文件
4. 创建并切换到memory分支
5. 初始提交
6. 提示用户设置远程分支

**初始化完成后**：

```
✓ 记忆系统初始化完成

终端已注册：【小黑：ubuntu】
Git分支已创建：memory

建议：如果有远程仓库，请设置远程分支：
  git push -u origin memory

现在可以开始使用HARVEST和SYNC命令。
```

### 7.2 新终端首次使用

**检测**：
- 系统已初始化
- 当前终端的 `system.json` 刚创建（last_sync 为 null）

**AI响应**：

```
检测到新终端：[hostname]

请输入环境名称（如：本地、ubuntu、生产等）：
```

用户输入后：

```
✓ 新终端已注册：【小黑：ubuntu】

正在执行首次同步...
```

然后执行SYNC的"新终端首次同步"流程。

### 7.3 发现记忆冲突

**检测**：
- 不同终端对同一问题/配置有不同的描述
- 通过关键词匹配识别

**AI响应**：

在SYNC输出中添加警告：

```
⚠️ 注意：检测到可能的配置冲突
  - 【大黑：本地】设置Redis连接池为200
  - 【小黑：本地】之前设置为100
  请确认哪个配置更合适，或根据环境区分。
```

或：

```
⚠️ 注意：发现不同的解决方案
  - 【大黑：本地】使用Celery处理异步任务
  - 【小黑：ubuntu】之前使用asyncio
  可能需要统一技术栈，或明确使用场景。
```

### 7.4 Git操作失败

**场景1：pull失败（网络问题）**

```
⚠️ 同步失败：无法连接到远程仓库

请检查网络连接或稍后重试。
本地记忆仍然可用。
```

**场景2：push失败（网络问题）**

```
✓ 已收获记忆 | 终端：【小黑：ubuntu】| 2025-11-16 18:45

（记忆列表）

⚠️ 注意：记忆已保存到本地，但推送到远程失败（网络问题）
下次SYNC或HARVEST时会自动重试推送
```

**场景3：merge冲突**

```
⚠️ 同步遇到合并冲突

记忆文件产生冲突，正在尝试自动解决...

[如果自动解决成功]
✓ 冲突已自动解决，同步完成

[如果无法自动解决]
⚠️ 无法自动解决冲突，需要手动处理
冲突文件：.memory/index/memory_index.json
请手动编辑文件解决冲突后，执行：
  git add .memory/index/memory_index.json
  git commit
  git push origin memory
然后重新执行SYNC
```

### 7.5 无重要变更（HARVEST时）

**检测**：
- 分析变更后发现都是琐碎修改
- 无需记录的内容

**AI响应**：

```
✓ 已扫描工作记录 | 终端：【小黑：ubuntu】| 2025-11-16 12:30

本次无重要记忆需要记录（仅有代码格式调整、注释补充等琐碎变更）
```

不执行Git提交和推送，节省资源。

### 7.6 长时间未HARVEST（主动提示）

**检测**：
- 距上次HARVEST超过4小时
- 且有超过5个新的Git提交

**AI响应**（在用户提问的回答末尾添加）：

```
（主要响应内容）
...

💡 提示：检测到自上次HARVEST以来已有8个新提交（距今6小时），建议在工作告一段落时执行HARVEST保存经验。
```

### 7.7 长时间未SYNC（主动提示）

**检测**：
- 距上次SYNC超过12小时
- 且memory分支有新提交（其他终端的更新）

**AI响应**（在用户提问的回答末尾添加）：

```
（主要响应内容）
...

💡 提示：检测到其他终端有新的工作记忆（距上次同步已12小时），建议执行SYNC学习最新知识。
```

---

## 8. 与用户交互规范

### 8.1 确认机制

#### 需要确认的情况

1. **HARVEST时推断可能不准确**：
   - 基于Git提交推断的工作内容
   - 用户在多个session工作后统一HARVEST
   - 变更较多且复杂

2. **首次初始化**：
   - 确认是否初始化记忆系统
   - 询问终端环境名称

3. **检测到冲突**：
   - 不同终端有矛盾的配置或方案
   - 需要用户确认哪个是对的

#### 确认的方式

**方式1：展示推断，询问补充**

```
观察到你在这个终端上进行了以下工作：

已完成（拟记录为中期记忆）：
1. Redis集成：检测到3个提交修改config/redis.py、utils/cache.py
   推断：实现了Redis缓存层
   
是否还有其他重要的经验、决策或需要记录的信息？
如果以上推断有误，请指出修正。
```

**方式2：是/否确认**

```
⚠️ 记忆系统尚未初始化

检测到这是首次使用跨终端记忆系统。
是否现在初始化？（将创建.memory/目录和相关配置）

回复"是"或"初始化"以开始。
```

**方式3：提供选项**

```
检测到可能的配置冲突：

选项A：【大黑：本地】Redis连接池200
选项B：【小黑：本地】Redis连接池100
选项C：根据环境区分（本地100，服务器200）

请选择或说明你的决策：
```

### 8.2 提示用户的时机

#### 适合主动提示的情况

1. 长时间未HARVEST且有大量新提交
2. 长时间未SYNC且有新记忆
3. 检测到记忆冲突
4. 系统建议执行CONSOLIDATE

#### 不应该提示的情况

1. 用户正在专注工作（正在调试、编码）
2. 刚刚执行过相关命令（1小时内）
3. 变更很少，不紧急

#### 提示的方式

**温和的建议**（不打断流程）：

```
💡 提示：检测到自上次HARVEST以来已有8个新提交，建议在工作告一段落时执行HARVEST保存经验。
```

**不要使用命令语气**：

❌ "你必须执行HARVEST"
❌ "现在执行SYNC"
✅ "建议执行HARVEST保存经验"
✅ "可以执行SYNC学习最新知识"

### 8.3 语言和语气

#### 基本原则

- **简洁**：用最少的文字传达必要信息
- **专业**：使用准确的技术术语
- **友好**：保持温和、支持性的语气
- **客观**：基于事实，不做主观评价

#### 用词规范

**推荐用词**：
- "检测到"、"观察到"、"分析发现"
- "推断"、"可能"、"建议"
- "已完成"、"进行中"、"待验证"

**避免用词**：
- "你应该"、"你必须"（太强制）
- "很好"、"完美"、"糟糕"（主观评价）
- "一些"、"若干"、"相关"（模糊）

#### 示例对比

❌ **不好的表达**：
"你做了一些很好的优化，但还有若干问题需要解决，你应该尽快处理。"

✅ **好的表达**：
"完成了查询优化（200ms→50ms），待在生产环境验证性能表现。"

---

## 9. 完整工作流程示例

### 9.1 场景1：新的一天开始工作

**上下文**：
- 用户昨天在【大黑：本地】工作
- 今天切换到【小黑：ubuntu】服务器环境
- 昨天完成了Redis集成

**对话流程**：

```
用户：SYNC

AI：✓ 同步完成 | 终端：【小黑：ubuntu】| 学习了 2 条新记忆

来自【大黑：本地】(2025-11-15):
  • Redis集成完成：Sentinel模式，3节点配置
  • 部署脚本优化：增加健康检查和自动回滚

用户：好的，我现在要开始优化数据库查询

AI：（正常工作响应）
了解。你可以从以下方面着手：
1. 分析慢查询日志
2. 检查是否需要添加索引
3. 考虑查询语句优化
...

（工作进行中...）

用户：我添加了一个复合索引，开发环境测试很快，但担心生产环境数据量大会有问题

AI：建议在staging环境进行测试：
1. 导入生产级别的数据量
2. 执行查询性能测试
3. 监控索引大小和查询时间
...

（工作继续...）
```

### 9.2 场景2：工作一天后离开

**上下文**：
- 在【小黑：ubuntu】工作了一天
- 完成了数据库查询优化
- 修复了一个登录bug
- 开始了API限流的实现但未完成

**对话流程**：

```
用户：HARVEST

AI：正在分析工作记录...

观察到你在这个终端上进行了以下工作：

已完成（拟记录为中期记忆）：
1. 数据库查询优化：检测到config/database.py、models/user.py的提交
   推断：添加了数据库索引优化查询性能
   
2. 登录bug修复：检测到auth/token_validator.py的修改
   推断：修复了Token验证相关问题

进行中（拟记录为短期记忆）：
3. API限流实现：检测到api/middleware.py有未提交修改
   推断：正在实现API限流功能

是否还有其他重要的经验、决策或需要记录的信息？
如果以上推断有误，请指出修正。

用户：第1点是对的，添加了复合索引(user_id, created_at)，查询从200ms降到50ms。第2点的根本原因是时区问题，Token过期判断用了本地时间而不是UTC。第3点我在考虑用Redis令牌桶算法，但还没决定。

AI：感谢补充。正在保存记忆...

✓ 已收获记忆 | 终端：【小黑：ubuntu】| 2025-11-16 18:45

中期记忆 (2条):
  • 数据库查询优化：复合索引(user_id, created_at)，200ms→50ms
  • 登录bug修复：Token时区问题，需用UTC时间

短期记忆 (1条):
  • API限流实现中：考虑Redis令牌桶算法

已推送到 origin/memory
```

### 9.3 场景3：新终端加入

**上下文**：
- 新买了一台电脑【大黑-毕业：ubuntu】
- 首次连接到项目
- 需要快速了解项目状态

**对话流程**：

```
用户：SYNC

AI：检测到新终端：dahei-biye

请输入环境名称（如：本地、ubuntu、生产等）：

用户：ubuntu

AI：✓ 新终端已注册：【大黑-毕业：ubuntu】

正在执行首次同步...

✓ 新终端初始化 | 终端：【大黑-毕业：ubuntu】

已学习综合记忆：
  架构：Django REST + Redis Sentinel + PostgreSQL
  部署：Docker Compose + Nginx + HTTPS证书自动续期
  关键配置：环境变量见.env.example，服务器Redis需密码
  已知问题：并发>1000时连接池可能耗尽，大数据集分页用游标

近期工作 (最近7天):
  • Redis集成、登录修复、查询优化
  • 部署脚本健康检查、API限流实现
  • NumPy依赖管理、测试覆盖率提升

准备就绪 ✓

用户：好的，我现在要继续API限流的工作

AI：根据记忆，API限流正在实现中，之前考虑使用Redis令牌桶算法。

当前状态：
- 文件：api/middleware.py（未完成）
- 方案：Redis令牌桶算法

你可以从以下步骤继续：
1. 确定限流策略（按IP、按用户、按endpoint）
2. 实现令牌桶逻辑
3. 集成到中间件
...
```

### 9.4 场景4：多个session工作后统一收获

**上下文**：
- 用户在3个不同的chat session中工作
- 完成了多个任务
- 现在统一执行HARVEST

**对话流程**：

```
用户：HARVEST

AI：正在分析工作记录...

检测到多个Git提交（10个），由于无法获取完整对话上下文，基于代码变更推断：

已完成（基于提交分析）：
1. Redis集成：5个提交，涉及config/redis.py、utils/cache.py等
   推断：完成了Redis缓存层集成
   
2. 认证模块修改：2个提交，涉及auth/目录多个文件
   推断：进行了认证相关的功能开发或修复

3. API接口调整：3个提交，涉及api/views.py、serializers.py
   推断：调整或新增了API接口

由于推断可能不够准确，请补充以下信息：
- 这些工作的具体目的和成果？
- 是否遇到了需要记录的问题或决策？
- 是否有特殊的注意事项？

用户：
1是对的，Redis用Sentinel模式，3个节点。
2是修复了一个登录bug，Token过期时间判断有问题。
3是新增了用户管理的API，支持批量操作。

AI：感谢详细说明。正在保存记忆...

✓ 已收获记忆 | 终端：【小黑：ubuntu】| 2025-11-16 20:30

中期记忆 (3条):
  • Redis集成完成：Sentinel模式，3节点配置
  • 登录bug修复：Token过期判断逻辑错误
  • 用户管理API：新增批量操作支持

已推送到 origin/memory
```

---

## 10. 技术实现细节（供AI理解）

### 10.1 文件系统结构

```
.memory/
├── config/
│   ├── system.json              # 终端配置（不同步，类似.env）
│   ├── system.json.example      # 配置模板
│   └── MEMORY-PROTOCOL.md       # 本协议文档
├── index/
│   ├── memory_index.json        # 记忆总索引
│   └── learning_status.json    # 各终端学习状态
├── archives/                    # 按终端归档
│   ├── xiaohei_local/
│   │   └── 2025-11-16_001.md
│   └── xiaohei_ubuntu/
│       └── 2025-11-16_001.md
├── active/                      # 活跃记忆
│   ├── short_term.md
│   ├── medium_term.md
│   └── consolidated.md
└── logs/                        # 操作日志
    ├── harvest_log.json
    ├── sync_log.json
    └── consolidate_log.json
```

### 10.2 脚本调用方式

AI应通过调用Python脚本执行记忆操作：

**SYNC命令**：
```bash
python .memory_scripts/memory_manager.py sync --terminal-id xiaohei_ubuntu
```

**HARVEST命令**：
```bash
python .memory_scripts/memory_manager.py harvest \
  --terminal-id xiaohei_ubuntu \
  --since "2025-11-15 18:30:00" \
  --interactive
```

**CONSOLIDATE命令**：
```bash
python .memory_scripts/memory_manager.py consolidate
```

**STATUS命令**：
```bash
python .memory_scripts/memory_manager.py status --terminal-id xiaohei_ubuntu
```

脚本会返回JSON格式的结果，AI解析后生成人类可读的输出。

### 10.3 数据流转

```
用户工作 → Git提交/文件变更
    ↓
HARVEST命令 → memory_manager.py分析
    ↓
生成记忆JSON → 写入归档文件
    ↓
更新索引和活跃记忆 → Git提交
    ↓
Git推送到memory分支
    ↓
其他终端拉取 → SYNC命令
    ↓
读取新记忆 → AI学习并向用户报告
    ↓
更新learning_status → 标记已学习
```

### 10.4 记忆索引结构

每条记忆在`memory_index.json`中的条目：

```json
{
  "id": "mem_20251116_001",
  "type": "medium_term",
  "category": "architecture",
  "source_terminal": "xiaohei_ubuntu",
  "source_terminal_display": "【小黑：Ubuntu】",
  "created_at": "2025-11-16T18:45:00Z",
  "title": "Redis集成完成",
  "summary": "Redis集成完成：Sentinel模式，3节点配置",
  "tags": ["redis", "cache", "deployment"],
  "learned_by": ["xiaohei_ubuntu", "dahei_local"],
  "status": "active",
  "archive_path": "archives/xiaohei_ubuntu/2025-11-16_001.md"
}
```

AI通过读取索引快速获取记忆摘要，需要详情时再读取归档文件。

---

## 11. 协议版本和更新

**当前版本**：1.0.0  
**发布日期**：2025-11-16  
**维护者**：项目开发者

### 版本历史

- **1.0.0** (2025-11-16): 初始版本发布

### 协议更新机制

当协议需要更新时：
1. 更新本文档
2. 更新`version`字段
3. 在所有终端执行SYNC以学习新版本协议
4. 必要时运行迁移脚本

---

## 附录A：快速参考卡

### 核心命令

| 命令 | 用途 | 时机 |
|------|------|------|
| SYNC | 同步记忆 | 开始工作前 |
| HARVEST | 收获记忆 | 工作结束时 |
| CONSOLIDATE | 整理记忆 | 每周一次 |
| MEMORY STATUS | 查看状态 | 随时 |

### 记忆层级

| 层级 | 生命周期 | 内容 |
|------|----------|------|
| 短期 | 7天 | 进行中的工作 |
| 中期 | 项目周期 | 架构、配置、已解决问题 |
| 长期 | 永久 | 通用最佳实践 |

### 输出格式关键要素

- 符号：✓ 成功，⚠️ 警告
- 终端：【计算机名：环境名】
- 记忆：主题（5-10字）：细节（10-20字）
- 时间：YYYY-MM-DD HH:MM

### 判断标准速查

**应该记录**：架构决策、非显而易见的bug、环境差异、性能优化、已知问题

**不应该记录**：格式调整、显而易见的修复、临时调试、例行更新

---

## 附录B：常见问题

### Q1：为什么HARVEST要基于实际变更而非对话历史？

**A**：因为用户可能在多个chat session中工作，依赖单一session的对话历史会导致信息不完整。基于Git提交、任务文件等实际变更更可靠。

### Q2：如果忘记执行HARVEST会怎样？

**A**：记忆不会自动生成。建议在每天工作结束时执行HARVEST。如果忘记了，后续执行时会分析自上次以来的所有变更。

### Q3：如果两个终端同时HARVEST会冲突吗？

**A**：可能会产生Git merge冲突，但系统会尝试自动解决。如果无法自动解决，会提示手动处理。

### Q4：记忆文件会越来越大吗？

**A**：CONSOLIDATE命令会定期整理，将短期记忆提升或遗忘，将中期记忆融入综合记忆并压缩，对抗信息熵增。

### Q5：如果在没有网络的环境工作？

**A**：可以正常使用HARVEST保存记忆到本地，下次有网络时会自动推送。SYNC需要网络拉取远程记忆。

### Q6：可以在记忆管理session之外执行HARVEST吗？

**A**：可以，但建议使用固定的记忆管理session以保持一致性和便于追踪历史。

### Q7：如果不小心记录了错误的记忆？

**A**：使用FORGET命令删除，或手动编辑记忆文件后重新提交。

### Q8：多个项目可以共享记忆系统吗？

**A**：本协议设计为单项目使用。如需跨项目，建议使用独立的"通用知识库"项目。

---

**协议结束**

如有疑问或需要更新协议，请联系项目维护者。

